{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "ADE_Dataset.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qpi4GGia3LW9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy\n",
        "import xlrd\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import re, string, unicodedata\n",
        "import os\n",
        "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
        "from pyspark.ml.feature import Word2Vec\n",
        "import spacy\n",
        "import math\n",
        "import nbconvert\n",
        "%matplotlib inline\n",
        "import glob\n",
        "#import gensim\n",
        "import nltk\n",
        "import inflection as inflect\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
        "from string import ascii_lowercase\n",
        "import itertools, snowballstemmer\n",
        "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
        "from pyspark.ml.feature import Word2Vec\n",
        "import spacy\n",
        "from matplotlib.colors import rgb2hex\n",
        "from matplotlib.patches import Polygon\n",
        "from pyspark.sql.session import SparkSession\n",
        "# instantiate Spark\n",
        "spark = SparkSession.builder.getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wigdG9943LXB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read the input csv data format\n",
        "drug_reaction_inputdf = pd.read_csv(\"drug_adverse_report_data.csv\",na_values=' ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JxGZPgY3LXD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check the number of rows and columns and account for total input data imported\n",
        "\n",
        "drug_reaction_inputdf.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkdW3q7o3LXF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Quality control for data type and the number of non null values in each column\n",
        "\n",
        "drug_reaction_inputdf.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqDtqa993LXH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drug_reaction_inputdf.isnull().sum(axis = 0)/len(drug_reaction_inputdf)*100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYCkRtFT3LXJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# count of zero values\n",
        "\n",
        "row_zero_count = (df[df == 0].count(axis=1)/len(df.columns))\n",
        "raw dataframe after dropping redaundant columns\n",
        "column_zero_count = (drug_reaction_inputdf[drug_reaction_inputdf == 0].count(axis=0)/len(drug_reaction_inputdf.index))*100\n",
        "column_zero_count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97h9v0-R3LXL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drug_reaction_inputdf.nunique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrnTX8xY3LXN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# show column 0 to 15 and 3 rows of dataframe\n",
        "drug_reaction_inputdf.iloc[:,0:15].head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4AidHAC3LXQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# show column 16 to 30 and 3 rows of dataframe\n",
        "\n",
        "drug_reaction_inputdf.iloc[:,16:30].head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMXLqogD3LXR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# show column 31 to 45 and 3 rows of dataframe\n",
        "\n",
        "drug_reaction_inputdf.iloc[:,31:45].head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Co9XLjl3LXT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# show column 36 to 54 and 3 rows of dataframe\n",
        "\n",
        "drug_reaction_inputdf.iloc[:,36:54].head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tVG-90x3LXV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# select numerical variables to display summary statistics(df.loc[:, df.dtypes == np.float64])\n",
        "\n",
        "selected_int_df = ['Patientsex','Patientonsetage','Drugenddate','Drugtreatmentduration','Drugcharacterization','Serious']\n",
        "\n",
        "drug_reaction_intgerdf = drug_reaction_inputdf[selected_int_df]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKn_ELAJ3LXW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drug_reaction_intgerdf.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIyxp5Qy3LXd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# count of zero values\n",
        "\n",
        "row_zero_count = (df[df == 0].count(axis=1)/len(df.columns))\n",
        "raw dataframe after dropping redaundant columns\n",
        "column_zero_count = (drug_reaction_inputdf[drug_reaction_inputdf == 0].count(axis=0)/len(drug_reaction_inputdf.index))*100\n",
        "column_zero_count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3C3FtkXM3LXe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drug_reaction_inputdf.nunique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lp7iNrJ63LXg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#sumary of data\n",
        "\n",
        "drug_reaction_inputdf.iloc[:,36:46].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVoD8IES3LXi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data cleaning\n",
        "# The data cleaning process is implemented to drop redundant and duplicated variables that are not required,\n",
        "# also create uniform datatypes in each column of dataframe.\n",
        "# This process of cleaning each column will remove meta characters, numerical value\n",
        "# in text columns and texts from numeric columns. This will produce same data type for all values of a\n",
        "# variable. It will increase accuracy of plots, data engineering and modelling.\n",
        "# The unique values in each columns will be examined for cleaning columns where necesary.\n",
        "# functions are creted to clean numeric and objects data types respectively\n",
        "# The count of unique values will be displayed before and after cleaning to check any deviation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leVI12wE3LXk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# select and remove duplicate columns\n",
        "\n",
        "drug_reaction_df1 = drug_reaction_inputdf.copy()\n",
        "\n",
        "duplicate_cols = ['drug Index (generated)','generic name Index (generated)','pharm class cs Index (generated)','pharm class epc Index (generated)',\n",
        "'pharm class pe Index (generated)', 'reaction Index (generated)','results Index (generated)',\n",
        " 'substance name Index (generated)','route Index (generated)']\n",
        "\n",
        "drug_reaction_df1 = drug_reaction_df1.drop(drug_reaction_df1[duplicate_cols], axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qBeRmBC3LXn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check Null values in each column, the columns with more than 70% of null values will be removed\n",
        "# check the percentage of null values\n",
        "#1.4 Function to calculate percentage of NaN missing values in each variable of the dataset. columns where 70 to 100% of values are Null are dropped at this stage\n",
        "\n",
        "def nan_percentage(df):\n",
        "    ''' calcute the percentage of NaN values for each column in the dataframe and return only columns containing NaN and the percentage'''\n",
        "    \n",
        "    nandf = df.loc[:, df.isnull().any()]  # get columns containing nan values\n",
        "    nan_percent = nandf.isnull().sum(axis = 0)/len(df)*100  # percentage of nan values\n",
        "    \n",
        "    return nan_percent\n",
        "# call the function\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGhjKqzf3LXo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# apply the nan_percent function\n",
        "\n",
        "df = drug_reaction_df1\n",
        "\n",
        "nan_percentage()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBUda-FE3LXq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "null_columns = ['Drugauthorizationnumb','Drugbatchnumb','Companynumb','Drugtreatmentduration',\n",
        "                'Drugtreatmentdurationunit','Companynumb','Seriousnessdisabling','Seriousnesslifethreatening',\n",
        "                'Seriousnesscongenitalanomali','Reportercountry','Safetyreportid']\n",
        "\n",
        "drug_reaction_df2 = drug_reaction_df1.copy()\n",
        "\n",
        "drug_reaction_df2 = drug_reaction_df2.drop(drug_reaction_df2[null_columns], axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGn3R9US3LXr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# apply the nan_percent function\n",
        "\n",
        "df = drug_reaction_df2\n",
        "\n",
        "nan_percentage()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BngRAbFE3LXt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Map the case lowering function to all column names #map(str.lower, df.columns) \n",
        "\n",
        "drug_reaction_df3 = drug_reaction_df2.copy()\n",
        "\n",
        "# lowercase column name amd remove space\n",
        "\n",
        "drug_reaction_df3.columns = drug_reaction_df3.columns.str.lower().str.replace(' ', '')\n",
        "\n",
        "drug_reaction_df3.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OQpo2Gv3LXv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 2.1 create a function to clean integer type data\n",
        "\n",
        "def integer_clean(df):\n",
        "    '''return dataframe for integer data to retain only the digits (and dot and minus sign).\n",
        "    This would remove characters, alphabets or anything that is not defined in to_replace attribute\n",
        "    quality control data after cleaning\n",
        "    '''\n",
        "    df = df.loc[:, df.dtypes == np.int64].replace(regex=True, to_replace=r'[^0-9.\\-]', value=r'')\n",
        "    \n",
        "    return df\n",
        "\n",
        "# call function"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udOGBL9f3LXx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 2.2 create a function to clean float type data.\n",
        "\n",
        "def float_clean(df):\n",
        "    '''return dataframe for integer data to retain only the digits (and dot and minus sign).\n",
        "    This would remove characters, alphabets or anything that is not defined in to_replace attribute\n",
        "    quality control data after cleaning\n",
        "    '''\n",
        "    df = df.loc[:, df.dtypes == np.float64].replace(regex=True, to_replace=r'[^0-9.\\-]', value=r'')\n",
        "    \n",
        "    return df\n",
        "   \n",
        "#call function"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJ4kXqOY3LXy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 2.3 create a function to clean string data.\n",
        "\n",
        "def clean_text(df = df, col= 'make'):\n",
        "    '''This function returns a pandas list object of the given dataframe and column.\n",
        "    The values of the column will be changed to lower case, remove spaces, punctuations and numbers,\n",
        "    replace lines with non ascii characters that might exist'''\n",
        "    \n",
        "    df[col]= df[col].str.strip().str.lower().str.replace(' ', '').str.replace('[^\\w\\s]','').apply(lambda x: x.translate(string.punctuation)).apply(lambda x: x.translate(string.digits)).str.replace('[#%\\'()*+,-./:;<=>?@\\[\\]^_`{|}~1234567890’”“′‘\\\\\\]','').str.replace(r'[^\\x00-\\x7f]', '')\n",
        "    \n",
        "    return df[col]\n",
        "    \n",
        "#call function"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZgzH6_k3LX0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# text data columns, check unique values of each text column before transformation. \n",
        "\n",
        "drug_reaction_textdf3 = drug_reaction_df3.loc[:, drug_reaction_df3.dtypes == 'object'].copy()\n",
        "\n",
        "drug_reaction_textdf3.nunique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ai_QcA9-3LX3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Exoloration Data Analyses\n",
        "The sub sets and groups of variables were visualised to gain insight on data distribution and\n",
        "relationship. The questions that guided the plots include.\n",
        "\n",
        "2.What are the most frequent words in the Drug dosage text?\n",
        "\n",
        "3.How do the categories vary with target variable?\n",
        "\n",
        "4.Which age category had more death adverse reaction?\n",
        "\n",
        "5.Which medicine products and route of intake were more involved in death drug adverse reaction?\n",
        "\n",
        "6.What is the count ratio of target variable? \n",
        "\n",
        "7.What is the effect of drug treatment duration on death drug adverse reaction?\n",
        "\n",
        "8.Is there a difference based on gender, weight and age on death adverse drug reaction?\n",
        "\"\"\"\n",
        "a = 'a'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FVpGnB73LX4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # 3.0 Exploratory Data Analysis and visualisation.\n",
        "'''\n",
        "The plots are produced using Matplotlib and Seaborn libraries\n",
        "\n",
        "give a differentiation or separation of the samples in the binary classifier.\n",
        "\n",
        "The visualisation will show relationship between input features or variables.\n",
        "\n",
        "Visualise data distribution of each variable for skew correction\n",
        "\n",
        "This will also help to discover trend and patterns in the data and to understand data characteristics.\n",
        "\n",
        "The Analysis is also aimed at discovering relationships in data engineering choice.\n",
        "\n",
        "Plot include univariate plots using Histogram, Barplot, Bivariate plots such as Boxplots, Multivariate scatter plots and cluster plots.\n",
        "'''\n",
        "plot ='plot'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mH1q4Y4F3LX5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The target variable for classification is seriousnessdeath\n",
        "# the value 1 represents death event due to adverse drug reation\n",
        "# \n",
        "\n",
        "drug_reaction_df33 = drug_reaction_df3.copy()\n",
        "\n",
        "drug_reaction_df33.seriousnessdeath = drug_reaction_df33.seriousnessdeath.fillna(0) # fill non death event with 0\n",
        "\n",
        "drug_reaction_df33.seriousnessdeath.unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6GjIqfN3LX7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drug_reaction_df33.pharmclassepc.unique()[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhx3ORQF3LX9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#3.1 BarPlot of target variable 'seriousnessdeath'\n",
        "plt.figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
        "sns.catplot(x=\"seriousnessdeath\", kind=\"count\",palette=\"ch:.25\", data=drug_reaction_df33)\n",
        "plt.title('Bar plot of Target variable seriousnessdeath')\n",
        "plt.xlabel('seriousnessdeath')\n",
        "plt.ylabel('Count of Values')\n",
        "plt.xticks(rotation='vertical')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrtnVmXG3LX-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The data is imbalanced\n",
        "# The number of drug reations that resulted in death are much less than non death adverse reation events \n",
        "\"\"\"\n",
        "pharmclasspe          28\n",
        "route                 29\n",
        "\"\"\"\n",
        "a='a'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAwUwzaR3LYA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.min(drug_reaction_df33.patientonsetage), np.max(drug_reaction_df33.patientonsetage)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mr7YDEA3LYB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# count of categorical values\n",
        "\n",
        "drug_reaction_df33['pharmclasspe_count'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0naPYNKe3LYD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Factor plot \n",
        "plt.figure(num=None, dpi=80,figsize =(14,6), facecolor='w', edgecolor='k')\n",
        "sns.catplot('pharmclasspe', 'patientonsetage', hue='seriousnessdeath', data=drug_reaction_df33, kind='bar')\n",
        "plt.title('Patient experience subset by seriousness death')\n",
        "plt.xlabel('pharm class physiological experience')\n",
        "plt.ylabel('patient age')\n",
        "plt.xticks(rotation='vertical')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ja6tF_f93LYE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Factor plot \n",
        "plt.figure(num=None, dpi=80,figsize =(14,6), facecolor='w', edgecolor='k')\n",
        "sns.catplot('route', 'patientweight', hue='seriousnessdeath', data=drug_reaction_df33, kind='bar')\n",
        "plt.title('Drug ntake route')\n",
        "plt.xlabel('route')\n",
        "plt.ylabel('patientweight')\n",
        "plt.xticks(rotation='vertical')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ra11LtrR3LYG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Histogram of 'patientweight'\n",
        "\n",
        "# Multiple plots boxplot and histograms in the same window\n",
        "# Cut the window in 2 parts\n",
        "f, (ax_box, ax_hist) = plt.subplots(2, figsize =(14,6),sharex=True, gridspec_kw={\"height_ratios\": (.15, .85)})\n",
        " \n",
        "# Add a graph in each part\n",
        "sns.boxplot(drug_reaction_df33[\"patientweight\"], ax=ax_box)\n",
        "sns.distplot(drug_reaction_df33[\"patientweight\"], ax=ax_hist) \n",
        "# Remove x axis name for the boxplot\n",
        "ax_box.set(xlabel='')\n",
        "plt.title('Boxplot and Histogram of patientweight')\n",
        "plt.xlabel('patientweight')\n",
        "plt.ylabel('frequency ditribution')\n",
        "plt.xticks(rotation='vertical')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nQdWVv-3LYI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# patientweight distribution is skwed and shows outliers hence has to be transformed\n",
        "# plot histogram of log transformation of EngineSize\n",
        "# Add 1 to replace zero before log transform\n",
        "\n",
        "drug_reaction_df33.loc[:,\"patientweightLog\"] = (drug_reaction_df33.loc[:,\"patientweight\"]+1).apply(np.log)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igDDN8Ps3LYJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Histogram of 'EngineSizeLog'\n",
        "# Multiple histograms in the same window\n",
        "# Cut the window in 2 parts\n",
        "f, (ax_box, ax_hist) = plt.subplots(2, figsize =(14,6),sharex=True, gridspec_kw={\"height_ratios\": (.15, .85)})\n",
        " \n",
        "# Add a graph in each part\n",
        "sns.boxplot(drug_reaction_df33[\"patientweightLog\"], ax=ax_box)\n",
        "sns.distplot(drug_reaction_df33[\"patientweightLog\"], ax=ax_hist) \n",
        "# Remove x axis name for the boxplot\n",
        "ax_box.set(xlabel='')\n",
        "plt.title('Boxplot and Histogram of patientweightLog')\n",
        "plt.xlabel('patientweightLog')\n",
        "plt.ylabel('frequency density')\n",
        "plt.xticks(rotation='vertical')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48B_rnZD3LYL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drug_reaction_df33.patientsex.unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SG60DM13LYN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# grouped boxplot\n",
        "drug_reaction_df33.patientsex = drug_reaction_df33.patientsex.fillna(0)\n",
        "sns.set(style=\"ticks\", palette=\"pastel\")\n",
        "\n",
        "# Draw a nested boxplot to show bills by day and time\n",
        "plt.figure(num=None, dpi=80,figsize =(14,6), facecolor='w', edgecolor='k')\n",
        "f, axes = plt.subplots(1, 1, figsize=(14, 14), sharex=True)\n",
        "sns.boxplot(x=\"patientsex\", y=\"patientweight\",\n",
        "            hue=\"seriousnessdeath\", palette=[\"m\", \"g\"],\n",
        "            data=drug_reaction_df33)\n",
        "sns.despine(offset=10, trim=True)\n",
        "plt.title('Boxplot of patientsex using patientweight, seriousnessdeath as legend' )\n",
        "plt.xlabel('patientsex')\n",
        "plt.ylabel('patientweight')\n",
        "plt.xticks(rotation='vertical')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJMmp0aF3LYP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# grouped boxplot\n",
        "\n",
        "sns.set(style=\"ticks\", palette=\"pastel\")\n",
        "\n",
        "# Draw a nested boxplot to show bills by day and time\n",
        "plt.figure(num=None, dpi=80,figsize =(14,6), facecolor='w', edgecolor='k')\n",
        "f, axes = plt.subplots(1, 1, figsize=(14, 14), sharex=True)\n",
        "sns.boxplot(x=\"route\", y=\"patientweight\",\n",
        "            hue=\"seriousnessdeath\", palette=[\"m\", \"g\"],\n",
        "            data=drug_reaction_df33)\n",
        "sns.despine(offset=10, trim=True)\n",
        "plt.title('Boxplot of route using patientweight, seriousnessdeath as legend' )\n",
        "plt.xlabel('route')\n",
        "plt.ylabel('patientweight')\n",
        "plt.xticks(rotation='vertical')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlnMJ7cT3LYR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baLq7w7X3LYS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Feature extraction, transformation and engineering\n",
        "# feature were extracted using word3vec in text variables with very high number of categorical values\n",
        "# Also numerical values such as Age was also categorised by biining into groups as seriousness of adverse drug effect\n",
        "# varies with age groups."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCVdX2sA3LYU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drug_reaction_df3.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVbPbx_I3LYW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  check the unique values of Drugdosagetext\n",
        "\n",
        "drug_reaction_df3.drugdosagetext[10:1000].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-UC0N7I3LYY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# comment\n",
        "# There are many unique values in the text columns,the data will be preprocessed by \n",
        "# replacing missing value\n",
        "# lower casing of the text\n",
        "# vectorisation of the values using word2vec "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjHYa79r3LYZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# change values to lower case and replace missing values\n",
        "\n",
        "drug_reaction_df3a = drug_reaction_df3.copy()\n",
        "\n",
        "drug_reaction_df3a.drugdosagetext = drug_reaction_df3a.drugdosagetext.str.lower().fillna('missing') # lower casing\n",
        "\n",
        "# display for quality control\n",
        "drug_reaction_df3a.drugdosagetext[10:1000].unique()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6kcn_O13LYa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a function to implement vectorisation of each text column\n",
        "# Comment The word2vec will be implemented using sparksession \n",
        "# A function is created to vectorise each of the ten text columns\n",
        "\n",
        "# 2.3 create a function to vectorise each text column.\n",
        "\n",
        "def text_vectorize():\n",
        "    '''This function returns a pandas dataframe and columns of word tokens and the vectors.\n",
        "    implement word2vec using spark session'''\n",
        "    \n",
        "    # select the tokenised word\n",
        "    word_df = tok_df.select('words') \n",
        "    \n",
        "    # Learn a mapping from words to Vectors.\n",
        "    text_word2Vec = Word2Vec(vectorSize=3, minCount=0, inputCol=\"words\", outputCol=\"result\")\n",
        "    \n",
        "    # fit model using data\n",
        "    text_model = text_word2Vec.fit(word_df)\n",
        "    \n",
        "    # transform using fitted model to output vectors\n",
        "    vec_df = text_model.transform(word_df)\n",
        "    \n",
        "    return vec_df\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6r_iu3Qe3LYc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# vectorize drugdosagetext column\n",
        "\n",
        "dosage_text_df = drug_reaction_df3a.loc[:,['drugdosagetext']].copy()\n",
        "\n",
        "# create pyspark dataframe\n",
        "dosage_text_spark = spark.createDataFrame(dosage_text_df)\n",
        "# tokenize\n",
        "tokenizer = Tokenizer(inputCol=\"drugdosagetext\", outputCol=\"words\") # tokenise the data in spark_df\n",
        "\n",
        "tok_df = tokenizer.transform(dosage_text_spark) # tokenize text\n",
        "\n",
        "# word vectors using function\n",
        "dosage_vec_df = text_vectorize()\n",
        "\n",
        "# display for QC of word vectors\n",
        "\n",
        "for row in dosage_vec_df.take(2):\n",
        "    print(row)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mC27VK93LYd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add the word vectors to dataframe\n",
        "\n",
        "# convert spark word vector list to pandas \n",
        "dosage_pd_df = dosage_vec_df.toPandas()\n",
        "\n",
        "# select result and create a list \n",
        "dosage_vec_list = dosage_pd_df['result'].tolist()   # convert to python list\n",
        "\n",
        "# convert to pandas dataframe\n",
        "dosage_vec_pd_df = pd.DataFrame(dosage_vec_list, columns=['dosagevec1', 'dosagevec2', 'dosagevec3'], index = range(92130)) # to datafram\n",
        "\n",
        "# set input dataframe index range\n",
        "drug_reaction_df3a.index = range(92130)\n",
        "\n",
        "# join the word vector columns to the main dataframe\n",
        "drug_reaction_df4 = pd.concat([drug_reaction_df3a, dosage_vec_pd_df], axis=1)\n",
        "\n",
        "drug_reaction_df4.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zygj0WE-3LYg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# medicinalproduct text column\n",
        "#change values to lower case and replace missing values\n",
        "\n",
        "drug_reaction_df5 = drug_reaction_df4.copy()\n",
        "\n",
        "drug_reaction_df5.medicinalproduct = drug_reaction_df5.medicinalproduct.str.lower().fillna('missing') # lower casing\n",
        "\n",
        "# display for quality control\n",
        "drug_reaction_df5.medicinalproduct[0:100].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwXLXYCt3LYk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# vectorize medicinalproduct\n",
        "\n",
        "medicine_text_df = drug_reaction_df5.loc[:,['medicinalproduct']].copy()\n",
        "\n",
        "# create pyspark dataframe\n",
        "medicine_text_spark = spark.createDataFrame(medicine_text_df)\n",
        "\n",
        "tokenizer = Tokenizer(inputCol=\"medicinalproduct\", outputCol=\"words\") # tokenise the data in spark_df\n",
        "\n",
        "tok_df = tokenizer.transform(medicine_text_spark) # tokenize text\n",
        "# output word vectors using function\n",
        "medicine_vec_df = text_vectorize()\n",
        "\n",
        "# display for QC of word vectors\n",
        "\n",
        "for row in medicine_vec_df.take(2):\n",
        "    print(row)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oq_dliG03LYo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add the word vectors to dataframe\n",
        "\n",
        "# convert spark word vector list to pandas \n",
        "medicine_pd_df = medicine_vec_df.toPandas()\n",
        "\n",
        "# select result and create a list \n",
        "medicine_vec_list = medicine_pd_df['result'].tolist()   # convert to python list\n",
        "\n",
        "# convert to pandas dataframe\n",
        "medicine_vec_pd_df = pd.DataFrame(medicine_vec_list, columns=['medvec1', 'medvec2', 'medvec3'], index = range(92130)) # to datafram\n",
        "\n",
        "# set input dataframe index range\n",
        "drug_reaction_df5.index = range(92130)\n",
        "\n",
        "# join the word vector columns to the main dataframe\n",
        "drug_reaction_df6 = pd.concat([drug_reaction_df5, medicine_vec_pd_df], axis=1)\n",
        "\n",
        "drug_reaction_df6.head(3)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCURXqL33LYq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# vectorise reactionmeddrapt\n",
        "\n",
        "# change values to lower case and replace missing values\n",
        "\n",
        "drug_reaction_df7 = drug_reaction_df6.copy()\n",
        "\n",
        "drug_reaction_df7.reactionmeddrapt = drug_reaction_df7.reactionmeddrapt.str.lower().fillna('missing') # lower casing\n",
        "\n",
        "# display for quality control\n",
        "drug_reaction_df7.reactionmeddrapt[10:100].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "987Zh7xE3LYs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# vectorize medicinalproduct\n",
        "\n",
        "reactionmed_text_df = drug_reaction_df7.loc[:,['reactionmeddrapt']].copy()\n",
        "\n",
        "# create pyspark dataframe\n",
        "reactionmed_text_spark = spark.createDataFrame(reactionmed_text_df)\n",
        "\n",
        "tokenizer = Tokenizer(inputCol=\"reactionmeddrapt\", outputCol=\"words\") # tokenise the data in spark_df\n",
        "\n",
        "tok_df = tokenizer.transform(reactionmed_text_spark) # tokenize text\n",
        "# output word vectors using function\n",
        "reactionmed_vec_df = text_vectorize()\n",
        "\n",
        "# display for QC of word vectors\n",
        "\n",
        "for row in reactionmed_vec_df.take(2):\n",
        "    print(row)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mbezh0Z73LYu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# vectorize reactionmeddrapt\n",
        "\n",
        "# Add the word vectors to dataframe\n",
        "\n",
        "# convert spark word vector list to pandas \n",
        "reaction_pd_df = reactionmed_vec_df.toPandas()\n",
        "\n",
        "# select result and create a list \n",
        "reaction_vec_list = reaction_pd_df['result'].tolist()   # convert to python list\n",
        "\n",
        "# convert to pandas dataframe\n",
        "reaction_vec_pd_df = pd.DataFrame(reaction_vec_list, columns=['reactionvec1', 'reactionvec2', 'reactionvec3'], index = range(92130)) # to datafram\n",
        "\n",
        "# set input dataframe index range\n",
        "drug_reaction_df7.index = range(92130)\n",
        "\n",
        "# join the word vector columns to the main dataframe\n",
        "drug_reaction_df8 = pd.concat([drug_reaction_df7, reaction_vec_pd_df], axis=1)\n",
        "\n",
        "drug_reaction_df8.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woyV96c73LYv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drug_reaction_df8.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ycg8I5HS3LYx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# vectorise drugindication\n",
        "\n",
        "# change values to lower case and replace missing values\n",
        "\n",
        "drug_reaction_df9 = drug_reaction_df8.copy()\n",
        "\n",
        "drug_reaction_df9.drugindication = drug_reaction_df9.drugindication.str.lower().fillna('missing') # lower casing\n",
        "\n",
        "# display for quality control\n",
        "drug_reaction_df9.drugindication[10:100].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDrJbP5H3LYy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# vectorize drugindication\n",
        "\n",
        "indication_text_df = drug_reaction_df9.loc[:,['drugindication']].copy()\n",
        "\n",
        "# create pyspark dataframe\n",
        "indication_spark = spark.createDataFrame(indication_text_df)\n",
        "\n",
        "tokenizer = Tokenizer(inputCol=\"drugindication\", outputCol=\"words\") # tokenise the data in spark_df\n",
        "\n",
        "tok_df = tokenizer.transform(indication_spark) # tokenize text\n",
        "# output word vectors using function\n",
        "indication_vec_df = text_vectorize()\n",
        "\n",
        "# display for QC of word vectors\n",
        "\n",
        "for row in indication_vec_df.take(2):\n",
        "    print(row)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH9Q14RJ3LY0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add the word vectors to dataframe\n",
        "\n",
        "# convert spark word vector list to pandas \n",
        "indication_pd_df = indication_vec_df.toPandas()\n",
        "\n",
        "# select result and create a list \n",
        "indication_vec_list = indication_pd_df['result'].tolist()   # convert to python list\n",
        "\n",
        "# convert to pandas dataframe\n",
        "indication_vec_pd_df = pd.DataFrame(indication_vec_list, columns=['indicationvec1', 'indicationvec2', 'indicationvec3'], index = range(92130)) # to datafram\n",
        "\n",
        "# set input dataframe index range\n",
        "drug_reaction_df9.index = range(92130)\n",
        "\n",
        "# join the word vector columns to the main dataframe\n",
        "drug_reaction_df10 = pd.concat([drug_reaction_df9, reaction_vec_pd_df], axis=1)\n",
        "\n",
        "drug_reaction_df10.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6A9fglV3LY1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# vectorise substancename\n",
        "\n",
        "# change values to lower case and replace missing values\n",
        "\n",
        "drug_reaction_df11 = drug_reaction_df10.copy()\n",
        "\n",
        "drug_reaction_df11.substancename = drug_reaction_df11.substancename.str.lower().fillna('missing') # lower casing\n",
        "\n",
        "# display for quality control\n",
        "drug_reaction_df11.substancename[10:100].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJf-s61V3LY3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# vectorize substancename\n",
        "\n",
        "substance_text_df = drug_reaction_df11.loc[:,['substancename']].copy()\n",
        "\n",
        "# create pyspark dataframe\n",
        "substance_spark = spark.createDataFrame(substance_text_df)\n",
        "\n",
        "tokenizer = Tokenizer(inputCol=\"substancename\", outputCol=\"words\") # tokenise the data in spark_df\n",
        "\n",
        "tok_df = tokenizer.transform(substance_spark) # tokenize text\n",
        "# output word vectors using function\n",
        "substance_vec_df = text_vectorize()\n",
        "\n",
        "# display for QC of word vectors\n",
        "\n",
        "for row in substance_vec_df.take(2):\n",
        "    print(row)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_shON7c3LY4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add the word vectors to dataframe\n",
        "\n",
        "# convert spark word vector list to pandas \n",
        "substance_pd_df = substance_vec_df.toPandas()\n",
        "\n",
        "# select result and create a list \n",
        "substance_vec_list = substance_pd_df['result'].tolist()   # convert to python list\n",
        "\n",
        "# convert to pandas dataframe\n",
        "substance_vec_pd_df = pd.DataFrame(substance_vec_list, columns=['substancevec1', 'substancevec2', 'substancevec3'], index = range(92130)) # to datafram\n",
        "\n",
        "# set input dataframe index range\n",
        "drug_reaction_df11.index = range(92130)\n",
        "\n",
        "# join the word vector columns to the main dataframe\n",
        "drug_reaction_df12 = pd.concat([drug_reaction_df11, substance_vec_pd_df], axis=1)\n",
        "\n",
        "drug_reaction_df12.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7P2n5Uct3LY6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# change values to lower case and replace missing values in pharmclassepc\n",
        "\n",
        "drug_reaction_df13 = drug_reaction_df12.copy()\n",
        "\n",
        "drug_reaction_df13.pharmclassepc = drug_reaction_df13.pharmclassepc.str.lower().fillna('missing') # lower casing\n",
        "\n",
        "# display for quality control\n",
        "drug_reaction_df13.pharmclassepc[10:100].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meRtDN0y3LY8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# vectorize substancename\n",
        "\n",
        "classepc_text_df = drug_reaction_df13.loc[:,['pharmclassepc']].copy()\n",
        "\n",
        "# create pyspark dataframe\n",
        "classepc_spark = spark.createDataFrame(classepc_text_df)\n",
        "\n",
        "tokenizer = Tokenizer(inputCol=\"pharmclassepc\", outputCol=\"words\") # tokenise the data in spark_df\n",
        "\n",
        "tok_df = tokenizer.transform(classepc_spark) # tokenize text\n",
        "# output word vectors using function\n",
        "classepc_vec_df = text_vectorize()\n",
        "\n",
        "# display for QC of word vectors\n",
        "\n",
        "for row in classepc_vec_df.take(2):\n",
        "    print(row)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDQ5fMLX3LY9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add the word vectors to dataframe\n",
        "\n",
        "# convert spark word vector list to pandas \n",
        "classepc_pd_df = classepc_vec_df.toPandas()\n",
        "\n",
        "# select result and create a list \n",
        "classepc_vec_list = classepc_pd_df['result'].tolist()   # convert to python list\n",
        "\n",
        "# convert to pandas dataframe\n",
        "classepc_vec_pd_df = pd.DataFrame(classepc_vec_list, columns=['classepcvec1', 'classepcvec2', 'classepcvec3'], index = range(92130)) # to datafram\n",
        "\n",
        "# set input dataframe index range\n",
        "drug_reaction_df13.index = range(92130)\n",
        "\n",
        "# join the word vector columns to the main dataframe\n",
        "drug_reaction_df14 = pd.concat([drug_reaction_df13, classepc_vec_pd_df], axis=1)\n",
        "\n",
        "drug_reaction_df14.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3oxKH9l3LY_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# vectorise pharmclasscs column\n",
        "\n",
        "# change values to lower case and replace missing values in pharmclassepc\n",
        "\n",
        "drug_reaction_df15 = drug_reaction_df14.copy()\n",
        "\n",
        "drug_reaction_df15.pharmclasscs = drug_reaction_df15.pharmclasscs.str.lower().fillna('missing') # lower casing\n",
        "\n",
        "# display for quality control\n",
        "drug_reaction_df15.pharmclasscs[10:100].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE4UpEk33LZC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# vectorize pharmclasscs\n",
        "\n",
        "pharmclasscs_text_df = drug_reaction_df15.loc[:,['pharmclasscs']].copy()\n",
        "\n",
        "# create pyspark dataframe\n",
        "pharmclasscs_spark = spark.createDataFrame(pharmclasscs_text_df)\n",
        "\n",
        "tokenizer = Tokenizer(inputCol=\"pharmclasscs\", outputCol=\"words\") # tokenise the data in spark_df\n",
        "\n",
        "tok_df = tokenizer.transform(pharmclasscs_spark) # tokenize text\n",
        "\n",
        "# output word vectors using function\n",
        "pharmclasscs_vec_df = text_vectorize()\n",
        "\n",
        "# display for QC of word vectors\n",
        "\n",
        "for row in pharmclasscs_vec_df.take(2):\n",
        "    print(row)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uves2jGp3LZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add the word vectors to dataframe\n",
        "\n",
        "# convert spark word vector list to pandas \n",
        "pharmclasscs_pd_df = pharmclasscs_vec_df.toPandas()\n",
        "\n",
        "# select result and create a list \n",
        "pharmclasscs_vec_list = pharmclasscs_pd_df['result'].tolist()   # convert to python list\n",
        "\n",
        "# convert to pandas dataframe\n",
        "pharmclasscs_vec_pd_df = pd.DataFrame(pharmclasscs_vec_list, columns=['pharmclasscsvec1', 'pharmclasscsvec2', 'pharmclasscsvec3'], index = range(92130)) # to datafram\n",
        "\n",
        "# set input dataframe index range\n",
        "drug_reaction_df15.index = range(92130)\n",
        "\n",
        "# join the word vector columns to the main dataframe\n",
        "drug_reaction_df16 = pd.concat([drug_reaction_df15, pharmclasscs_vec_pd_df], axis=1)\n",
        "\n",
        "drug_reaction_df16.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUZ-b-dJ3LZG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# change values to lower case and replace missing values in pharmclasspe\n",
        "\n",
        "drug_reaction_df17 = drug_reaction_df16.copy()\n",
        "\n",
        "drug_reaction_df17.pharmclasspe = drug_reaction_df17.pharmclasspe.str.lower().fillna('missing') # lower casing\n",
        "\n",
        "# display for quality control\n",
        "drug_reaction_df17.pharmclasspe[10:100].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NbHrkpN3LZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# vectorize  pharmclasspe\n",
        "\n",
        "pharmclasspe_text_df = drug_reaction_df17.loc[:,['pharmclasspe']].copy()\n",
        "\n",
        "# create pyspark dataframe\n",
        "pharmclasspe_spark = spark.createDataFrame( pharmclasspe_text_df)\n",
        "\n",
        "tokenizer = Tokenizer(inputCol=\"pharmclasspe\", outputCol=\"words\") # tokenise the data in spark_df\n",
        "\n",
        "tok_df = tokenizer.transform(pharmclasspe_spark) # tokenize text\n",
        "\n",
        "# output word vectors using function\n",
        "pharmclasspe_vec_df = text_vectorize()\n",
        "\n",
        "# display for QC of word vectors\n",
        "\n",
        "for row in pharmclasspe_vec_df.take(2):\n",
        "    print(row)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmmUlTlK3LZI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add the word vectors to dataframe\n",
        "\n",
        "# convert spark word vector list to pandas \n",
        "pharmclasspe_pd_df = pharmclasspe_vec_df.toPandas()\n",
        "\n",
        "# select result and create a list \n",
        "pharmclasspe_vec_list = pharmclasspe_pd_df['result'].tolist()   # convert to python list\n",
        "\n",
        "# convert to pandas dataframe\n",
        "pharmclasspe_vec_pd_df = pd.DataFrame(pharmclasspe_vec_list, columns=['pharmclasspevec1', 'pharmclasspevec2', 'pharmclasspevec3'], index = range(92130)) # to datafram\n",
        "\n",
        "# set input dataframe index range\n",
        "drug_reaction_df17.index = range(92130)\n",
        "\n",
        "# join the word vector columns to the main dataframe\n",
        "drug_reaction_df18 = pd.concat([drug_reaction_df17, pharmclasspe_vec_pd_df], axis=1)\n",
        "\n",
        "drug_reaction_df18.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trNAQ-Gq3LZL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# change values to lower case and replace missing values in route\n",
        "\n",
        "drug_reaction_df19 = drug_reaction_df18.copy()\n",
        "\n",
        "drug_reaction_df19.route = drug_reaction_df19.route.str.lower().fillna('missing') # lower casing\n",
        "\n",
        "# display for quality control\n",
        "drug_reaction_df19.route.unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LFfiaAi3LZN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drug_reaction_df19.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkWKT_-I3LZP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# vectorize  route\n",
        "\n",
        "route_text_df = drug_reaction_df19.loc[:,['route']].copy()\n",
        "\n",
        "# create pyspark dataframe\n",
        "route_spark = spark.createDataFrame(route_text_df)\n",
        "\n",
        "tokenizer = Tokenizer(inputCol=\"route\", outputCol=\"words\") # tokenise the data in spark_df\n",
        "\n",
        "tok_df = tokenizer.transform(route_spark) # tokenize text\n",
        "\n",
        "# output word vectors using function\n",
        "route_vec_df = text_vectorize()\n",
        "\n",
        "# display for QC of word vectors\n",
        "\n",
        "for row in route_vec_df.take(2):\n",
        "    print(row)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzVKJxtj3LZR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add the word vectors to dataframe\n",
        "\n",
        "# convert spark word vector list to pandas \n",
        "route_pd_df = route_vec_df.toPandas()\n",
        "\n",
        "# select result and create a list \n",
        "route_vec_list = route_pd_df['result'].tolist()   # convert to python list\n",
        "\n",
        "# convert to pandas dataframe\n",
        "route_vec_pd_df = pd.DataFrame(route_vec_list, columns=['routevec1', 'routevec2', 'routevec3'], index = range(92130)) # to datafram\n",
        "\n",
        "# set input dataframe index range\n",
        "drug_reaction_df19.index = range(92130)\n",
        "\n",
        "# join the word vector columns to the main dataframe\n",
        "drug_reaction_df20 = pd.concat([drug_reaction_df19, route_vec_pd_df], axis=1)\n",
        "\n",
        "drug_reaction_df20.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vHm4XYK3LZS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#save out data to csv\n",
        "\n",
        "# Save the cleaned dataframe to disk1 as a csv file\n",
        "\n",
        "drug_reaction_df20.to_csv(\"drug_reaction_df20.csv\")   # save out the data to disc\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKdaCwUZ3LZU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# drop vectorized columns\n",
        "# drop vectorised columns\n",
        "text_drop_cols = ['drugdosagetext','drugindication','genericname','medicinalproduct','pharmclasscs','pharmclasscs',\n",
        "                  'pharmclassepc','pharmclasspe','reactionmeddrapt','route','substancename']\n",
        "drug_reaction_df21 = drug_reaction_df20.copy()\n",
        "drug_reaction_df21 = drug_reaction_df21.drop(drug_reaction_df21[text_drop_cols], axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hv-ZfLmN3LZV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drug_reaction_df21.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diWpg3A73LZX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# patientonsetage and patientweight contain missing values\n",
        "# Hence replace missing values with median and bin the variables\n",
        "# The variables containing missing values are not skews hence the column mean value will be used to imput missing values\n",
        "\n",
        "drug_reaction_df22 = drug_reaction_df21.copy()\n",
        "\n",
        "drug_reaction_df22 = drug_reaction_df22.iloc[:,1:54]\n",
        "\n",
        "# missing value for patientweight\n",
        "drug_reaction_df22['patientweight'] = drug_reaction_df22['patientweight'].fillna((drug_reaction_df22['patientweight'].median()))\n",
        "\n",
        "# missing value for patientonsetage\n",
        "drug_reaction_df22['patientonsetage'] = drug_reaction_df22['patientonsetage'].fillna((drug_reaction_df22['patientonsetage'].median()))\n",
        "\n",
        "# fill with mean as the values are not skewed\n",
        "\n",
        "drug_reaction_df22['patientsex'] = drug_reaction_df22['patientsex'].fillna((drug_reaction_df22['patientsex'].mean()))\n",
        "\n",
        "drug_reaction_df22['qualification'] = drug_reaction_df22['qualification'].fillna((drug_reaction_df22['qualification'].mean()))\n",
        "\n",
        "drug_reaction_df22['serious'] = drug_reaction_df22['serious'].fillna((drug_reaction_df22['serious'].mean()))\n",
        "\n",
        "# seriousnessdeath is the target variable,values are 1 and 0\n",
        "drug_reaction_df22.seriousnessdeath = drug_reaction_df22.seriousnessdeath.fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyvBYQVn3LZY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drug_reaction_df22.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZ27onoM3LZZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "count_df = drug_reaction_df22[['patientonsetage','patientweight']].copy()\n",
        "count_df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbTV9PrJ3LZb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# bining age and weight\n",
        "# bining for patientonsetage\n",
        "\n",
        "drug_reaction_df22['patientonsetagebin'] = pd.cut(drug_reaction_df22.patientonsetage,bins=4,labels=range(1, 5), retbins=False,include_lowest=True)\n",
        "\n",
        "drug_reaction_df22['patientonsetagebin'] = drug_reaction_df22['patientonsetagebin'].astype('int64')\n",
        "\n",
        "drug_reaction_df22['patientweightbin'] = pd.cut(drug_reaction_df22.patientweight,bins=4,labels=range(1, 5), retbins=False,include_lowest=True)\n",
        "\n",
        "drug_reaction_df22['patientweightbin'] = drug_reaction_df22['patientweightbin'].astype('int64')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAXbkv0Q3LZc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drug_reaction_df22['patientonsetagebin'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LD5ne0lI3LZd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drug_reaction_df22.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JSgQBcE3LZe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# drop columns after feature extraction\n",
        "\n",
        "# drop patientage and patientweight\n",
        "drug_reaction_df23 = drug_reaction_df22.copy()\n",
        "drug_reaction_df23 = drug_reaction_df23.drop(drug_reaction_df23[['patientonsetage','patientweight','drugadministrationroute',\n",
        "                                                                 'drugenddate','drugenddateformat','drugstartdate',\n",
        "                                                                 'drugstartdateformat','patientonsetageunit','receiptdate',\n",
        "                                                                 'receiptdateformat','receivedateformat',\n",
        "                                                                 'seriousnessother','seriousnesshospitalization',\n",
        "                                                                 'seriousnessother','transmissiondate',\n",
        "                                                                 'transmissiondateformat','receivedate','seriousnessdeath']], axis = 1)\n",
        "drug_reaction_df23['seriousnessdeath'] = drug_reaction_df22['seriousnessdeath']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4khP-4Sm3LZg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot of correlation matrix\n",
        "\n",
        "# Compute the correlation matrix\n",
        "corr = drug_reaction_df23.corr()\n",
        "\n",
        "# Generate a mask for the upper triangle\n",
        "mask = np.zeros_like(corr, dtype=np.bool)\n",
        "mask[np.triu_indices_from(mask)] = True\n",
        "\n",
        "# Set up the matplotlib figure\n",
        "f, ax = plt.subplots(figsize=(11, 9))\n",
        "\n",
        "# Generate a custom diverging colormap\n",
        "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
        "\n",
        "# Draw the heatmap with the mask and correct aspect ratio\n",
        "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
        "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7aJCYMc3LZh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Features and target data, split the model training and test data\n",
        "\n",
        "drug_reaction_df24 = drug_reaction_df23.copy()\n",
        "features_df= drug_reaction_df24.drop(['seriousnessdeath'], axis = 1) # features output\n",
        "\n",
        "target_df = drug_reaction_df24['seriousnessdeath']  # target output\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gV6rXU03LZh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVzlzXeR3LZj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drug_reaction_df24['seriousnessdeath'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiAuU_rA3LZj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTXIbR5w3LZl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# features scaling\n",
        "# Feature scaling improves the convergence of steepest descent algorithms, which do not possess \n",
        "#the property of scale invariance\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "std_scale = preprocessing.StandardScaler().fit(features_df)\n",
        "df_std = std_scale.transform(features_df)\n",
        "features_scaled_df = df_std\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkrpz8IU3LZm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#5.1  Train test splitting\n",
        "from __future__ import print_function\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "\n",
        "# Make a train/test split using 20% test size\n",
        "X_train, X_test, y_train, y_test = train_test_split(features_scaled_df, target_df,\n",
        "                                                    test_size=0.20,\n",
        "                                                    random_state=21)\n",
        "\n",
        "print(\"X_train dataset: \", X_train.shape)\n",
        "print(\"y_train dataset: \", y_train.shape)\n",
        "print(\"X_test dataset: \", X_test.shape)\n",
        "print(\"y_test dataset: \", y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAp4FRbL3LZn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Resample: Oversampling the training data using SMOTE\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train==1)))\n",
        "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train==0)))\n",
        "\n",
        "sm = SMOTE(random_state=2)\n",
        "X_train_res, y_train_res = sm.fit_sample(X_train, y_train.ravel())\n",
        "\n",
        "print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape))\n",
        "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape))\n",
        "\n",
        "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res==1)))\n",
        "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res==0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMegMhsL3LZp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Feature Seletion  (Recursive Feature Elimination)\n",
        "# Recursive Feature Elimination (RFE) repeatedly constructs a model and choose eitherthe best or worst \n",
        "# performing features. The goal of RFE is to select features by recursively considering smaller \n",
        "# and smaller sets of features.\n",
        "\n",
        "y=target_df\n",
        "X=features_df\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logreg = LogisticRegression(solver='lbfgs',max_iter=200, random_state=0)\n",
        "rfe = RFE(logreg, 20)\n",
        "rfe = rfe.fit(X_train, y_train)\n",
        "print(rfe.support_)\n",
        "print(rfe.ranking_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtZjW-Fn3LZq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rfe_score = rfe.score(X_test,y_test)\n",
        "print(rfe_score)\n",
        "print(sorted(zip(map(lambda x: round(x, 4),rfe_score), \n",
        "                 names), reverse=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zHbdeRj3LZr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create logistic regression model using the resample data\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve, auc, roc_auc_score, roc_curve, recall_score,classification_report\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufdsO6LP3LZs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 5.0 Model fitting\n",
        "#In the binary classification task, the following models are fitted and comapred using different \n",
        "# evaluation metrics. Logistic regression, NaiveBias, SVm, RandomForest, XGboost\n",
        "# Gradient Descent parameter optimisation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cnyf2xOV3LZt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Logistic regaression\n",
        "# Allfeatures are selected as good for modelling. \n",
        "\n",
        "lr = LogisticRegression(C=1.0,solver='lbfgs',max_iter=250, random_state=0)\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "#Score is Mean Accuracy\n",
        "logistic_score = lr.score(X_test,y_test)\n",
        "print( 'logisticregression score: ', logistic_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bWD6cLJ3LZu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Grid search optimisation\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Create logistic regression\n",
        "lrg = LogisticRegression(random_state=0,max_iter=200,solver='lbfgs' )             # initialize the model\n",
        "\n",
        "# parameter grid\n",
        "max_iter=[200,250,300,350]\n",
        "C = [1.0,1.5,2.0,2.5]\n",
        "# Create hyperparameter options\n",
        "param_grid = dict(max_iter=max_iter,C=C)\n",
        "\n",
        "# Grid search\n",
        "random = RandomizedSearchCV(estimator=lrg, param_distributions=param_grid, cv = 10, scoring = 'accuracy')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Al42c2Lw3LZv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random_result = random.fit(X_train, y_train)\n",
        "# Summarize results\n",
        "print(\"Best: %f using %s\" % (random_result.best_score_, random_result.best_params_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chLqcYIs3LZw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluate the classifier by using accuracy measure\n",
        "# Apply the trained Classifier to the test data (which, remember, it has never seen before to measure accuracy)\n",
        "print(\"classifier accuracy:\", random.score(X_test, y_test))  # score model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBH_LP1c3LZx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# predict with best model\n",
        "# Evaluate the classifier by using confusion matrix compare y predicted to actual y values\n",
        "\n",
        "# Apply the trained Classifier to the X-test data and make predictions\n",
        "y_pred = random.predict(X_test)  # use model to predict on test data for generalisation\n",
        "y_true = y_test\n",
        "# create confusion matrix\n",
        "\n",
        "confusion_matrix(y_true, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pl-Mrh3Q3LZy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.crosstab(y_true, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xw_VGQ5X3LZz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# precision, recall, F1-score\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "precision_recall_fscore_support(y_true, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQwEifjV3LZ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_names = ['class 0', 'class 1']\n",
        "print(classification_report(y_true, y_pred, target_names=target_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPwO9E3M3LZ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# RandomForest classifier\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import roc_auc_score\n",
        "# Create a random forest Classifier. By convention, rf, put hyperparameters, default\n",
        "rf = RandomForestClassifier(random_state=0)\n",
        "\n",
        "# Train the Classifier to take the X-training features and learn how they \n",
        "# relate to the y-training target independent variable\n",
        "\n",
        "rf.fit(X_train, y_train)  # fit model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHFEfyV73LZ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluate Randomforest\n",
        "print(\"classifier accuracy:\", rf.score(X_test, y_test))  # score model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5TkD7U83LZ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Apply the trained Classifier to the X-test data and make predictions\n",
        "rfy_pred = rf.predict(X_test)  # use model to predict on test data for generalisation\n",
        "y_true = y_test\n",
        "# create confusion matrix\n",
        "\n",
        "confusion_matrix(y_true, rfy_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-IfkcyV3LZ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(classification_report(y_true, rfy_pred, target_names=target_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qycNz8e23LaA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot of precission and Recall curve \n",
        "\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "precision, recall, _ = precision_recall_curve(y_test, rfy_pred)\n",
        "\n",
        "plt.step(recall, precision, color='b', alpha=0.2,\n",
        "         where='post')\n",
        "plt.fill_between(recall, precision, step='post', alpha=0.2,\n",
        "                 color='b')\n",
        "\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.title('2-class Precision-Recall curve')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrwZ5gUG3LaB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ROC curve\n",
        "fpr_rf, tpr_rf, _ = roc_curve(y_test, rfy_pred)\n",
        "roc_auc_rf = auc(fpr_rf, tpr_rf)\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.xlim([-0.01, 1.00])\n",
        "plt.ylim([-0.01, 1.01])\n",
        "plt.plot(fpr_rf, tpr_rf, lw=1, label='{} curve (AUC = {:0.2f})'.format('RF',roc_auc_rf))\n",
        "\n",
        "\n",
        "plt.xlabel('False Positive Rate', fontsize=16)\n",
        "plt.ylabel('True Positive Rate', fontsize=16)\n",
        "plt.title('ROC curve', fontsize=16)\n",
        "plt.legend(loc='lower right', fontsize=13)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=1, linestyle='--')\n",
        "plt.axes().set_aspect('equal')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdYwg00k3LaC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# feature Importance\n",
        "# Rank of the importance of feature\n",
        "rf.feature_importances_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Rnll2j_3LaD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# feature importance\n",
        "\n",
        "feature_importances = pd.DataFrame(rf.feature_importances_,index = features_df.columns,\n",
        "                                   columns=['importance']).sort_values('importance',ascending=False)\n",
        "\n",
        "feature_importances.head(34)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MBHqvFn3LaE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import knearest neighbors Classifier model\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "#Create KNN Classifier\n",
        "knn = KNeighborsClassifier(n_neighbors=7)\n",
        "\n",
        "#Train the model using the training sets\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "knny_pred = knn.predict(X_test)\n",
        "\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, knny_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PuXMCAR3LaE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(classification_report(y_true, knny_pred, target_names=target_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dXILFYt3LaF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The more data intensive estimators gave better performance precision and recall than logistic regresion \n",
        "# Comparison of prediction accuracy by the models shows that logistic regression, random Forest and K nearest Neighbour\n",
        "# gave the similar performance accuracy\n",
        "# based on the data.\n",
        "\n",
        "# Accuracy on obtained are as follws logistic regression 0.9361228698578096, RandomForest 0.9810593726256377 \n",
        "# and K Nearest neighbour 0.968305655052643\n",
        "# The results from these models shows that with more data, feature engineering and hyperparameter tunning\n",
        "# on RandomForest and KNN, the performance will be improved."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tmav47fN3LaG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot hyper parameter test random Forest\n",
        "'''\n",
        "N_estimators\n",
        "n_estimators represents the number of trees in the forest.\n",
        "Usually the higher the number of trees the better to learn the data.\n",
        "However, adding a lot of trees can slow down the training process considerably,\n",
        "therefore we do a parameter search to find the sweet spot.\n",
        "'''\n",
        "n_estimators = [1, 2, 4, 8, 16, 32, 64, 100, 500]\n",
        "train_results = []\n",
        "test_results = []\n",
        "for estimator in n_estimators:\n",
        "   rf = RandomForestClassifier(n_estimators=estimator, n_jobs=-1)\n",
        "   rf.fit(X_train, y_train)\n",
        "   train_pred = rf.predict(X_train)\n",
        "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n",
        "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
        "   train_results.append(roc_auc)\n",
        "   y_pred = rf.predict(X_test)\n",
        "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
        "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
        "   test_results.append(roc_auc)\n",
        "from matplotlib.legend_handler import HandlerLine2D\n",
        "line1, = plt.plot(n_estimators, train_results, label= \"Train AUC\")\n",
        "line2, = plt.plot(n_estimators, test_results, label=\"Test AUC\")\n",
        "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
        "plt.ylabel(\"AUC score\")\n",
        "plt.xlabel(\"n_estimators\")\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f72eulKZ3LaH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#max_depth\n",
        "'''\n",
        "max_depth represents the depth of each tree in the forest. The deeper the tree,\n",
        "the more splits it has and it captures more information about the data. \n",
        "We fit each decision tree with depths ranging from 1 to 32 and plot \n",
        "the training and test errors.\n",
        "'''\n",
        "max_depths = np.linspace(1, 100, 100, endpoint=True)\n",
        "train_results = []\n",
        "test_results = []\n",
        "for max_depth in max_depths:\n",
        "    rf = RandomForestClassifier(n_estimators= 100,max_depth=max_depth, n_jobs=-1)\n",
        "    rf.fit(X_train, y_train)\n",
        "    train_pred = rf.predict(X_train)\n",
        "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n",
        "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
        "    train_results.append(roc_auc)\n",
        "    y_pred = rf.predict(X_test)\n",
        "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
        "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
        "    test_results.append(roc_auc)\n",
        "from matplotlib.legend_handler import HandlerLine2D\n",
        "line1, = plt.plot(max_depths, train_results, \"b\", label=\"Train AUC\")\n",
        "line2, = plt.plot(max_depths, test_results, \"r\", label=\"Test AUC\")\n",
        "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
        "plt.ylabel(\"AUC score\")\n",
        "plt.xlabel(\"Tree depth\")\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}